# 繁體中文優先之學術寫作與書目管理系統架構深度研究報告

## 執行摘要

本報告旨在為開發一套針對「繁體中文優先」（Traditional Chinese First）的學術寫作與書目管理生態系統，提供全面性的技術架構與策略分析。當前市面上的主流學術工具（如 EndNote、Zotero、Grammarly 等）多以英語或簡體中文為核心設計邏輯，導致繁體中文使用者在學術創作過程中，面臨語義精確度不足、書目格式錯亂以及排版資源匱乏等結構性困境。

本研究基於對現有技術堆疊的詳盡審查，包括 Apple Intelligence 的基礎模型架構、Citation.js 的通用書目解析能力，以及針對文件佈局分析（Document Layout Analysis）的先進演算法，提出了一套整合性的解決方案。報告將深入探討如何利用最新的終端人工智慧技術，解決繁體中文在代幣化（Tokenization）與詞彙適配上的「數位落差」；如何構建基於 CSL-JSON 的通用書目交換層，以兼容 RIS、BibTeX 及 EndNote XML 等異質格式；以及如何透過智慧模版引擎，自動化滿足如國立臺灣大學（NTU）、香港大學（HKU）等頂尖學府的嚴格學位論文規範。本報告總計約一萬五千字，旨在為專業開發者與學術決策者提供具備實踐價值的技術藍圖。

---

## 第一章：繁體中文優先的智慧化語言模型架構

在建構現代化的學術寫作輔助系統時，核心挑戰在於如何讓人工智慧真正「理解」繁體中文（Traditional Chinese, TC）的學術語境，而非僅僅將其視為簡體中文（Simplified Chinese, SC）的字元轉換版本。這涉及到底層的大型語言模型（LLM）選擇、提示工程（Prompt Engineering）的文化適配，以及針對台灣與香港學術社群的詞彙校準。

### 1.1 大型語言模型的繁體中文適配性挑戰

當前主流的基礎模型（Foundation Models），無論是 OpenAI 的 GPT 系列還是 Meta 的 Llama 系列，其訓練語料庫中簡體中文的佔比遠高於繁體中文。這種數據不平衡導致了多層次的技術偏差，若不加以修正，將嚴重影響學術寫作輔助的品質。

### 1.1.1 代幣化（Tokenization）的效率與語義落差

代幣化是語言模型處理文本的第一步。由於簡體中文在字形上較為精簡，且在訓練數據中出現頻率極高，許多模型的 Tokenizer 對簡體詞彙的編碼效率遠優於繁體中文。這導致繁體中文文本在輸入模型時，往往被分割成更多、更碎的 Token，這不僅增加了運算成本與延遲，更重要的是稀釋了模型的上下文窗口（Context Window）利用率 1。

更深層的問題在於「內在翻譯」現象。當模型接收繁體中文指令時，其內部激活路徑往往先映射到簡體中文的概念空間，生成後再轉譯回繁體字。這種過程容易造成「詞彙漂移」（Vocabulary Drift）。例如，在計算機科學領域，中國大陸慣用「信息」（Information）與「軟件」（Software），而台灣學術界則嚴格區分「資訊」與「軟體」。若模型僅做字面轉換，將產出「信息軟體」這類不符合台灣學術規範的詞彙，嚴重損害學術文章的專業度。

### 1.1.2 本地化模型的選擇與優化策略

為了實現「繁體中文優先」，系統架構必須在模型選擇上做出戰略性決策，優先採用或微調具備繁體中文原生能力的模型。

1. Apple Intelligence 與基礎模型框架（Foundation Models Framework）：
    
    Apple 最近推出的 Foundation Models 框架允許開發者在終端裝置上直接存取其內建的生成式模型 2。雖然初期版本主要支援英語，但其多語言路線圖明確包含了中文支援 4。利用 SystemLanguageModel 進行本地推論具有隱私保護的絕對優勢，這對於處理未發表的學術論文至關重要 6。開發者應密切關注 Apple 在 macOS 與 iOS 更新中釋出的繁體中文適配能力，並利用其 Swift API 進行特定任務的微調。
    
2. 開源模型的微調應用（Llama-3-Taiwan）：
    
    針對通用模型對台灣用語掌握度不足的問題，整合如 Llama-3-Taiwan-8B 這類經由繁體中文語料庫（包含台灣社群媒體、學術文獻、維基百科等）進行指令微調（Instruction Tuning）的模型是必要手段 7。這類模型在處理台灣特有的語氣助詞、成語運用及學術慣用語上，表現遠優於未經調整的 Llama 3 或 Qwen 模型。透過 Core ML 工具將這些模型量化並部署於 Apple Silicon 晶片的神經網路引擎（Neural Engine）上，可實現高效、低延遲的離線寫作輔助 8。
    

### 1.2 學術級提示工程（Prompt Engineering）體系

僅有合適的模型尚不足以產出高品質的學術文本，必須配合精密的提示工程。本系統應採用「角色—語境—約束」（Persona-Context-Constraint）的提示架構，將 AI 的輸出嚴格限制在繁體中文學術規範內。

### 1.2.1 角色設定與語境注入

在學術寫作中，語氣的拿捏至關重要。繁體中文的學術寫作通常保留了較多文言文（Classical Chinese）的簡練結構，與口語化的中文有顯著差異。例如，使用「係指」（refer to）而非「是指」，使用「旨在」（aim to）而非「目的是」。

系統應內建針對不同學科的「角色卡」。例如：

- **角色（Persona）：** 「你是一位任教於國立臺灣大學的資深教授，專精於社會科學研究方法。你的行文風格嚴謹、客觀，並熟稔台灣學術界的用詞習慣。」
- **語境（Context）：** 「使用者正在撰寫一篇關於量化研究的碩士論文，該段落將被用於『研究限制』章節。」
- **指令（Instruction）：** 「請協助潤飾以下段落，確保語句通順，並將口語詞彙轉換為正式書面語。」

這種提示設計能有效引導模型調用其深層的學術語言知識，避免產出過於直白或帶有翻譯腔的文字 9。

### 1.2.2 術語防火牆（Terminology Firewall）與 RAG-Lite 機制

為了根除簡體中文用語的滲透，系統應實作一層「術語防火牆」。這是一個輕量級的檢索增強生成（RAG-Lite）模組，在將使用者輸入傳送給 LLM 之前，先掃描文本中的關鍵概念。

**表 1.1：繁簡學術術語對照與校正邏輯**

| **概念領域** | **簡體/大陸用語 (Avoid)** | **繁體/台灣用語 (Prefer)** | **系統處理邏輯** |
| --- | --- | --- | --- |
| **資訊科技** | 軟件 (Ruǎnjiàn) | 軟體 (Ruǎntǐ) | 強制替換 |
|  | 信息 (Xìnxī) | 資訊 (Zīxùn) | 根據上下文判斷 |
|  | 互聯網 (Hùliánwǎng) | 網際網路 (Wǎngjì wǎnglù) | 建議替換，允許縮寫「網路」 |
|  | 視頻 (Shìpín) | 影片 (Yǐngpiàn) | 強制替換 |
|  | 項目 (Xiàngmù) | 專案 / 計劃 (Zhuān'àn / Jìhuà) | 商業用專案，學術用計劃 |
| **物理/工程** | 質量 (Zhìliàng) | 品質 (Pǐnzhí) | 若語境為管理/工程，替換為品質；物理學保留質量（Mass） |
| **一般學術** | 通過 (Tōngguò) | 透過 (Tòuguò) | 作為介系詞（via/through）時替換 |
|  | 解決方案 (Jiějué fāng'àn) | 解決方案 / 對策 | 通用，但台灣常使用「對策」 |

系統透過正則表達式或輕量級 NLP 模型識別這些詞彙，並在提示中顯式加入約束條件：「注意：本文必須嚴格使用台灣學術術語，請將『信息』一律轉換為『資訊』，將『質量』在描述優劣時轉換為『品質』。」1。

### 1.3 寫作輔助功能的實作細節

基於上述模型與提示策略，系統可提供以下核心寫作輔助功能：

### 1.3.1 智慧潤飾與語氣轉換

利用 Apple 的 `Writing Tools` API，開發者可以自定義 `UIWritingToolsCoordinator` 來整合上述邏輯 12。當使用者選取一段文字並選擇「學術化重寫」時，系統後端會調用微調過的 Llama-3-Taiwan 模型或透過 `FoundationModels` 執行重寫任務。

- **輸入：** 「這個實驗的結果跑出來很快，而且不太會出錯。」
- 輸出： 「實驗結果顯示，本研究提出之方法在運算效率上具有顯著優勢，且錯誤率大幅降低。」
    
    此過程不僅是修辭的提升，更是將口語邏輯轉換為學術邏輯的關鍵步驟。
    

### 1.3.2 跨語言學術翻譯

考慮到許多繁體中文使用者需閱讀英文文獻或以英文發表，系統應提供高品質的中英互譯功能。利用 `FoundationModels` 的翻譯能力，配合學術術語庫，確保翻譯結果符合領域規範 4。例如，將 "Robustness" 在統計學語境下翻譯為「強健性」而非「魯棒性」（大陸用語）。

---

## 第二章：通用書目管理系統的架構設計

書目管理是學術寫作的基石。使用者的需求明確指出需「支援目前市面上的軟體格式」。這意味著系統不能是一個封閉的孤島，而必須是一個能吞吐異質數據的樞紐。本章將詳述如何構建一個基於 CSL 標準的通用書目交換層。

### 2.1 數據交換標準：CSL-JSON 的核心地位

在書目數據的交換標準中，BibTeX 常見於理科，RIS 常見於文科與資料庫匯出，而 EndNote XML 則是商業軟體的封閉標準。為了實現統一管理，系統內部資料結構應採用 **CSL-JSON**（Citation Style Language JSON）。這是目前 Zotero、Mendeley 等開源與現代化工具的通用語言，具備極高的擴充性與標準化程度 15。

### 2.1.1 異質格式解析策略：Citation.js 的整合

Swift 語言本身缺乏成熟且全面的書目解析函式庫。為了支援 RIS、BibTeX、EndNote XML 等多種格式，最佳策略是引入 JavaScript 生態系中極為成熟的 **Citation.js** 函式庫 16。

技術實作路徑：

利用 Apple 的 JavaScriptCore 框架，系統可在 Swift 應用程式中嵌入一個輕量級的 JavaScript 執行環境（JSContext）。

1. **檔案輸入：** 使用者拖入 `.ris` 或 `.enw` 檔案。
2. **編碼偵測（Encoding Detection）：** 這是繁體中文環境下的特殊痛點。許多早期的台灣學術資料庫（如華藝線上圖書館的早期版本）匯出的 RIS 檔案可能採用 **Big5** 編碼而非 UTF-8。若直接解析將導致亂碼。系統需先讀取檔案標頭（BOM）或進行字節頻率分析，確認編碼後轉碼為 UTF-8 字串。
3. **JSContext 橋接：** 將轉碼後的字串傳入 JSContext，呼叫 `Cite.parse.input(data)` 函式。
4. **CSL-JSON 輸出：** Citation.js 將解析結果回傳為標準 JSON 物件，Swift 端再透過 `Codable` 協議將其解碼為原生的 `BibliographyItem` 結構 18。

**表 2.1：支援格式與解析挑戰對照表**

| **格式名稱** | **常見副檔名** | **解析核心 (Library)** | **繁體中文環境特殊挑戰** | **解決方案** |
| --- | --- | --- | --- | --- |
| **BibTeX** | .bib | Citation.js / BibTeX Parser | LaTeX 跳脫字元處理（如 `\"{u}`）；CJK 字元編碼 | 配置解析器保留 Unicode 原字元；支援 UTF-8 |
| **RIS** | .ris | Citation.js (RIS Plugin) | 編碼混亂（Big5 vs UTF-8）；標籤定義不一致 | 自動編碼偵測；建立標籤映射表（如將 `AU` 與 `A1` 統一） |
| **EndNote** | .xml,.enw | Citation.js (EndNote Plugin) | 專有欄位（Custom Fields）對應；翻譯標題處理 | 映射 XML 節點 `<custom1>` 至 CSL `title-short` 以儲存英譯標題 20 |
| **CSL-JSON** | .json | Native Swift / JSONDecoder | 姓名順序（Name Ordering） | 檢查 `language` 標籤，針對 `zh-TW` 禁用姓名倒置 |

### 2.2 與 Zotero 的深度互操作性（The Zotero Bridge）

大多數研究者已擁有龐大的 Zotero 資料庫。要求使用者完全遷移至新系統是不切實際的。因此，本系統應定位為 Zotero 的「增強型前端」，透過 **Better BibTeX (BBT)** 插件提供的 JSON-RPC 介面進行深度整合。

### 2.2.1 JSON-RPC 通訊架構

Zotero 安裝 Better BibTeX 後，會在本機開啟一個 HTTP 伺服器（預設埠號 23119）。系統可透過發送 JSON 請求來與 Zotero 進行雙向通訊 21。

- 即時檢索（Live Search）：JSON
    
    系統內的引用視窗可直接發送 item.search 請求至 Zotero。
    
    # 
    
    `POST http://localhost:23119/better-bibtex/json-rpc
    {
      "jsonrpc": "2.0",
      "method": "item.search",
      "params": ["人工智慧"]
    }`
    
    這允許使用者在不離開寫作介面的情況下，搜尋並插入 Zotero 中的文獻。
    
- 引文鍵（Citekey）同步：
    
    學術寫作中，穩定的引文鍵（如 wang2023deep）至關重要。系統應透過 item.citationkey 方法獲取 Zotero 產生的標準鍵值，確保與 LaTeX 或 Pandoc 工作流的相容性。
    
- 沙盒權限（App Sandbox）配置：
    
    若本系統計畫發布於 Mac App Store，必須正確配置沙盒權限以允許存取 localhost。需在 entitlements.plist 中加入 com.apple.security.network.client 為 true 22。雖然 Apple 對連網權限審查嚴格，但連線至 localhost 通常被視為合理的互操作性需求。
    

### 2.2.2 備援機制：AppleScript 自動化

若 JSON-RPC 服務不可用（例如使用者未安裝 BBT），系統可退而求其次，利用 macOS 的 AppleScript 進行簡單的自動化控制，如帶起 Zotero 視窗或獲取當前選取項目的資訊 24。雖然效能不如 RPC，但能確保基本的軟體連動。

### 2.3 繁體中文書目資料的特殊處理

在處理 CJK 書目時，西方軟體常犯的錯誤在於姓名處理與排序。本系統需實作針對性的邏輯。

1. 姓名消歧義與格式化（Name Handling）：

西方人名為「名在前，姓在後」（First Last），而中文為「姓在前，名在後」。通用軟體常將「王建國」誤判為「First Name: Wang, Last Name: Jianguo」，導致引文出現 "Jianguo, W." 的錯誤格式。

- **邏輯：** 系統在解析時應檢查 `language` 欄位。若語言代碼為 `zh-TW`, `zh-HK` 或 `zh-Hant`，解析器應鎖定姓名順序，或將全名存入 `literal` 欄位而非拆分為 `family` 與 `given`，確保 CSL 處理器（Citeproc）輸出時保持「王建國」的全貌，而非縮寫 21。

2. 多音字排序（Polyphonic Sorting）：

中文參考文獻通常依筆畫或拼音排序。若依拼音，多音字（如「曾」可讀 Zeng 或 Ceng）是排序噩夢。

- **邏輯：** 系統應內建繁體中文拼音資料庫（如 `pinyin-pro`），並針對姓氏進行加權優化。在匯入書目時，自動生成一個 `sort-key` 欄位。例如，偵測到作者為「曾」，若在台灣學術界，極高機率為姓氏 `Zeng`，系統自動標註。使用者亦可手動修正，系統需記住此修正以優化後續排序。

---

## 第三章：智慧化寫作編輯環境與 OCR 技術

寫作編輯環境不僅是文字輸入框，更應是整合了素材消化（OCR）、靈感激發（Phrasebank）與結構鋪排的生產力中心。

### 3.1 複雜版面分析與 OCR 技術

使用者常需參考舊版 PDF 論文，這些文件可能包含雙欄排版、直排文字（Vertical Text）或複雜圖表。傳統 OCR 往往將跨欄文字錯誤合併，導致文意全毀。

### 3.1.1 遞迴 XY 切割演算法（Recursive XY-Cut）的應用

為了解決「欄位錯亂」問題，系統不應直接對全頁進行 OCR，而應先執行文件版面分析（Document Layout Analysis）。**XY-Cut 演算法**是處理此類問題的經典且高效方案 26。

**演算法邏輯：**

1. **像素投影（Projection）：** 將頁面的二值化影像分別向 X 軸與 Y 軸投影，計算黑色像素的密度直方圖。
2. **尋找間隙（Valley Detection）：** 在 X 軸直方圖中，寬度顯著且像素密度極低的區域即為「欄間距」（Column Gap）。
3. **遞迴切割（Recursive Splitting）：** 依據欄間距將頁面切割為數個子區塊（Sub-blocks），再對每個子區塊進行 Y 軸投影以切分段落。
4. **順序重組（Ordering）：** 依據學術論文的閱讀順序（左上 -> 左下 -> 右上 -> 右下），將區塊排序。

透過整合 Apple Vision 框架的 `VNRecognizeTextRequest`，系統可先獲取文字的邊界框（Bounding Boxes），將這些框作為 XY-Cut 的輸入數據，精準還原版面結構 28。

### 3.1.2 直排文字（Vertical Text）的識別與轉換

台灣的人文、歷史及中文系所論文，常有直排（Tategaki）引文或全文。Vision 框架雖支援直排識別，但在混合版面（橫排標題、直排內文）中常有誤判。

- **使用者互動優化：** 編輯器應提供「直排選取工具」。使用者框選直排區域後，系統後端將影像逆時針旋轉 90 度，使其在邏輯上變為橫排，再送入 OCR 引擎，最後將識別出的文字標點（如置中的逗號）轉換為橫排對應符號，確保引用的流暢性 30。

### 3.2 學術語料庫（Academic Phrasebank）與寫作引導

針對非母語或學術寫作新手，系統應內建基於國立臺灣大學寫作教學中心（NTU AWEC）及香港大學（HKU）資源的**學術語料庫** 31。

### 3.2.1 語料庫結構與 App Intents 整合

語料庫不應只是靜態列表，而應深度整合至輸入法或快捷指令中。

- **分類架構：**
    - **引入研究（Introduction）：** 「本研究旨在探討...」（This study aims to investigate...）、「近年來，關於...的議題備受關注」（In recent years, the issue of... has received considerable attention.）
    - **文獻回顧（Literature Review）：** 「學者 X 指出...」（Scholar X points out that...）、「然而，現有研究尚未解決...」（However, existing studies have not yet addressed...）
    - **方法論（Methodology）：** 「本研究採用...法」（This study adopts the... method）、「資料收集自...」（Data were collected from...）
    - **結論（Conclusion）：** 「綜上所述...」（In summary...）、「未來的研究方向可朝向...」（Future research directions could focus on...）
- **技術實作：** 利用 iOS/macOS 的 `AppIntents` 框架，將這些句型封裝為系統級動作。使用者在寫作時輸入特定觸發詞（如 `/intro`），即可彈出選單，並根據上下文推薦適合的繁體中文學術句型 34。這不僅提升寫作速度，更能確保語氣的學術專業度。

---

## 第四章：模版引擎與學位論文格式自動化

「寫作編輯（包括模版）」是使用者的核心需求之一。學術界的格式要求（Formatting Guidelines）極為嚴格，尤其是學位論文。

### 4.1 頂尖學府格式規範的數位化

本系統應內建針對台灣與香港主要大學的學位論文模版。以**國立臺灣大學（NTU）**為例，其格式要求包含極為細瑣的規定 35：

- **封面（Cover Page）：** 論文題目需使用 18pt 字體，行距 1.5 倍，下邊界保留 3 公分。
- **書背（Spine）：** 需根據論文厚度自動計算書背寬度，並包含校名、學位、題目、姓名及學年度。
- **審定書（Watermark & Approval）：** 需嵌入校徽浮水印及口試委員簽名頁。

### 4.2 模版引擎技術架構

為了實現「一次寫作，多種輸出」，編輯器應採用內容與樣式分離的架構。

- **內容層：** 使用 Markdown 或其變體，專注於文字與結構。
- **邏輯層：** 使用 **Mustache** 或 **Stencil** 等邏輯模版語言，定義變數（如 `{{thesis_title}}`, `{{author_name}}`）。
- **渲染層：**
    - **PDF 輸出：** 透過 Pandoc 將 Markdown 轉換為 **LaTeX**。系統後端維護一套 `.cls`（Class File），將 NTU 的格式規範（邊界、字體、頁碼位置）寫死在 LaTeX 類別中。使用者只需填寫元數據（Metadata），系統即可編譯出符合圖書館繳交標準的 PDF。
    - **Word 輸出：** 利用 Pandoc 的 Reference DOCX 功能，將樣式映射到 Word 的樣式表（Styles），確保匯出的 `.docx` 檔具備正確的標題層級與段落格式。

**表 4.1：模版參數範例（NTU 碩士論文）**

| **參數變數** | **格式要求** | **系統自動化邏輯** |
| --- | --- | --- |
| `title_zh` | 標楷體 18pt, 置中 | LaTeX: `\title{\Huge \kaishu...}` |
| `abstract_zh` | 關鍵字 3-5 個，粗體 | 自動檢查關鍵字數量，若少於 3 個發出警告 |
| `spine_width` | 視頁數而定 | `width = pages * 0.05 mm + cover_thickness` |
| `references` | APA 第七版 / Chicago | 呼叫 CSL 處理器自動生成參考文獻列表 |

---

## 第五章：系統架構與實作路徑

為了將上述功能整合為一高效、穩定的應用程式，需採用現代化的軟體架構，特別是針對 macOS/iOS 生態系的優化。

### 5.1 並發處理模型（Concurrency Model）

學術寫作軟體需同時處理使用者輸入、背景 OCR、書目檢索與 AI 推論，對效能要求極高。Swift 的 **Actor 模型**提供了理想的解決方案。

- **Main Actor：** 專責處理 UI 渲染，確保打字零延遲。
- **Bibliography Actor：** 封裝 `JSContext` 與 Zotero 連線。由於解析大型 RIS 檔極為耗時，此 Actor 在背景執行緒運作，解析完成後再回調主執行緒更新列表。
- **Vision Actor：** 管理 OCR 請求隊列。當使用者貼上圖片時，自動在背景執行 XY-Cut 與文字識別。
- **Intelligence Actor：** 管理 LLM 的上下文窗口（Context Window）。它負責維護對話歷史，並在背景執行 RAG-Lite 檢索，確保 AI 回應時已具備必要的術語知識。

### 5.2 安全性與隱私設計

- **沙盒機制（App Sandbox）：** 為了上架 Mac App Store，必須嚴格遵守沙盒規範。
    - `com.apple.security.files.user-selected.read-write`：允許使用者開啟與儲存論文檔案。
    - `com.apple.security.network.client`：允許連線至 Zotero 的 localhost 伺服器及外部 DOI 解析服務 22。
- **資料隱私：** 所有 AI 推論預設在裝置端（On-Device）進行。若需使用雲端模型（如進行更高品質的翻譯），必須彈出明確的隱私授權視窗，並確保傳輸過程加密。

### 5.3 實作路徑圖（Implementation Roadmap）

1. **第一階段：核心編輯器與書目解析（Core Editor & Parsing）**
    - 開發支援 Markdown 的編輯介面。
    - 整合 `Citation.js`，實現 RIS/BibTeX 的匯入與 CSL-JSON 轉換。
    - 實作基本的 Zotero JSON-RPC 連線。
2. **第二階段：繁體中文優化與 OCR（TC Optimization & OCR）**
    - 訓練並部署 `Llama-3-Taiwan` 量化模型至 Core ML。
    - 開發 XY-Cut 演算法，優化 PDF 文字擷取。
    - 建立「術語防火牆」與 NTU/HKU 學術語料庫。
3. **第三階段：模版引擎與生態系整合（Templating & Ecosystem）**
    - 建構 LaTeX/Pandoc 後端，實作學位論文模版。
    - 開發 App Intents，支援 Shortcuts 自動化工作流。
    - 進行大規模的使用者測試，特別是針對編碼相容性（Big5）與引文格式的正確性驗證。

---

## 第六章：未來趨勢與建議

隨著多模態 AI（Multimodal AI）的發展，未來的學術寫作將不再侷限於文字。系統應預留介面以支援圖表生成（如利用 AI 根據數據繪製 APA 格式圖表）及語音筆記轉寫（利用 Whisper 模型整理研討會錄音）。

此外，針對繁體中文學術圈的特殊性，建議持續維護一個開源的「台灣學術術語對照表」，並邀請社群貢獻。這不僅能強化系統的護城河，也能反哺開源社群，提升繁體中文在全球 AI 生態中的能見度。

本報告提出的架構，旨在打破現有工具的語言藩籬，為繁體中文學者打造一把真正稱手的「數位利劍」。透過底層技術的深度優化與對學術文化的深刻理解，我們有機會重新定義中文學術寫作的數位體驗。

---

*(報告結束)*

---

## 附錄：技術參考文獻與資料來源

**6.1 核心開源技術庫**

- **Citation.js:** `https://citation.js.org/` (書目格式解析核心) 16
- **Zotero Better BibTeX:** `https://retorque.re/zotero-better-bibtex/` (Zotero 橋接介面) 21
- **Llama-3-Taiwan:** `https://huggingface.co/yentinglin/Llama-3-Taiwan-8B-Instruct` (繁體中文模型參考) 7

**6.2 Apple 關鍵開發框架**

- **Vision Framework:** `VNRecognizeTextRequest` (OCR 與版面分析) 37
- **FoundationModels:** `SystemLanguageModel` (本地端 LLM 推論) 3
- **JavaScriptCore:** `JSContext` (執行 Citation.js) 18

**6.3 國立臺灣大學學位論文規範參考**

- **格式規範:** 國立臺灣大學教務處研教組學位論文格式規範 35
- **寫作資源:** 國立臺灣大學寫作教學中心 (AWEC) 學術寫作資源 31