#!/usr/bin/env python3
"""
ç”¨ tw-function-call-reasoning-10k è³‡æ–™é›†æ¸¬è©¦èˆ‡æ”¹é€² OVEREND AI åŠŸèƒ½

åŠŸèƒ½ï¼š
1. æå–é«˜å“è³ª Few-shot ç¯„ä¾‹ç”¨æ–¼æ”¹é€² Prompt
2. ç”Ÿæˆé©åˆ OVEREND ä½¿ç”¨çš„ç¹ä¸­ Tool Calling ç¯„ä¾‹
3. åˆ†æè³‡æ–™é›†ä¸­çš„æ€è€ƒéç¨‹æ¨¡å¼

ä½¿ç”¨æ–¹æ³•:
    source .venv/bin/activate
    python scripts/enhance_ai_with_dataset.py
"""

from datasets import load_dataset
import json
import os
from pathlib import Path
from typing import List, Dict, Any

# è¼‰å…¥è³‡æ–™é›†
print("ğŸ”„ è¼‰å…¥ tw-function-call-reasoning-10k è³‡æ–™é›†...")
ds = load_dataset('twinkle-ai/tw-function-call-reasoning-10k', split='train')
print(f"âœ… è¼‰å…¥å®Œæˆï¼å…± {len(ds)} ç­†è³‡æ–™")


# ========================================
# 1. æå– Few-shot ç¯„ä¾‹
# ========================================

def extract_fewshot_examples(keywords: List[str], limit: int = 5) -> List[Dict]:
    """æ ¹æ“šé—œéµå­—æå–é©åˆä½œç‚º Few-shot ç¯„ä¾‹çš„è³‡æ–™"""
    examples = []
    for example in ds:
        query = example['query_zhtw']
        if any(kw in query for kw in keywords):
            examples.append({
                'query': example['query_zhtw'],
                'think': example['think'],
                'answer': json.loads(example['answer']) if isinstance(example['answer'], str) else example['answer'],
                'tools': json.loads(example['tools']) if isinstance(example['tools'], str) else example['tools']
            })
            if len(examples) >= limit:
                break
    return examples


def generate_fewshot_prompt(examples: List[Dict]) -> str:
    """ç”Ÿæˆ Few-shot Prompt æ¨¡æ¿"""
    prompt_parts = []
    
    for i, ex in enumerate(examples, 1):
        tool_names = [t['name'] for t in ex['tools'][:3]]
        prompt_parts.append(f"""
### ç¯„ä¾‹ {i}
ä½¿ç”¨è€…æŒ‡ä»¤: {ex['query'][:100]}...
å¯ç”¨å·¥å…·: {', '.join(tool_names)}
æ€è€ƒéç¨‹: {ex['think'][:200]}...
ç­”æ¡ˆ: {json.dumps(ex['answer'], ensure_ascii=False)[:200]}...
""")
    
    return "\n".join(prompt_parts)


# ========================================
# 2. åˆ†æ Chain-of-Thought æ¨¡å¼
# ========================================

def analyze_cot_patterns(sample_size: int = 100) -> Dict[str, int]:
    """åˆ†æ Chain-of-Thought æ¨ç†ä¸­çš„å¸¸è¦‹æ¨¡å¼"""
    patterns = {
        'æª¢è¦–å¯ç”¨çš„åŠŸèƒ½': 0,
        'åƒæ•¸åˆ†æ': 0,
        'æ­¥é©Ÿåˆ†è§£': 0,
        'é©—è­‰é‚è¼¯': 0,
        'é¦–å…ˆ/ç„¶å¾Œ/æœ€å¾Œ': 0,
    }
    
    for example in ds.select(range(sample_size)):
        think = example['think']
        if 'æª¢è¦–' in think or 'æŸ¥çœ‹' in think:
            patterns['æª¢è¦–å¯ç”¨çš„åŠŸèƒ½'] += 1
        if 'åƒæ•¸' in think:
            patterns['åƒæ•¸åˆ†æ'] += 1
        if 'ç¬¬ä¸€' in think or 'æ­¥é©Ÿ' in think:
            patterns['æ­¥é©Ÿåˆ†è§£'] += 1
        if 'ç¢ºèª' in think or 'é©—è­‰' in think:
            patterns['é©—è­‰é‚è¼¯'] += 1
        if 'é¦–å…ˆ' in think or 'ç„¶å¾Œ' in think or 'æœ€å¾Œ' in think:
            patterns['é¦–å…ˆ/ç„¶å¾Œ/æœ€å¾Œ'] += 1
    
    return patterns


# ========================================
# 3. ç”Ÿæˆ OVEREND å°ˆç”¨ç¯„ä¾‹
# ========================================

def generate_overend_examples():
    """ç”Ÿæˆé©åˆ OVEREND å­¸è¡“å¯«ä½œå·¥å…·çš„ç¯„ä¾‹æ ¼å¼"""
    
    # æ¨¡æ“¬ OVEREND å·¥å…·å®šç¾©
    overend_tools = [
        {
            "name": "analyzeWriting",
            "description": "åˆ†æå­¸è¡“å¯«ä½œå…§å®¹ï¼Œæª¢æŸ¥èªæ³•ã€é¢¨æ ¼å’Œé‚è¼¯å•é¡Œ",
            "parameters": {
                "text": {"description": "è¦åˆ†æçš„æ–‡æœ¬", "type": "str"},
                "academicMode": {"description": "æ˜¯å¦ä½¿ç”¨å­¸è¡“æ¨¡å¼", "type": "bool", "default": True}
            }
        },
        {
            "name": "rewriteText",
            "description": "æ”¹å¯«æ–‡æœ¬ï¼Œå¯é¸æ“‡ä¸åŒé¢¨æ ¼ï¼šformalã€academicã€conciseã€elaborate",
            "parameters": {
                "text": {"description": "åŸå§‹æ–‡æœ¬", "type": "str"},
                "style": {"description": "æ”¹å¯«é¢¨æ ¼", "type": "str", "default": "academic"}
            }
        },
        {
            "name": "translateAcademic",
            "description": "é€²è¡Œå­¸è¡“ç¿»è­¯ï¼Œä¿ç•™å°ˆæ¥­è¡“èª",
            "parameters": {
                "text": {"description": "è¦ç¿»è­¯çš„æ–‡æœ¬", "type": "str"},
                "sourceLang": {"description": "ä¾†æºèªè¨€", "type": "str"},
                "targetLang": {"description": "ç›®æ¨™èªè¨€", "type": "str"}
            }
        },
        {
            "name": "extractPDFMetadata",
            "description": "å¾ PDF ä¸­æå–æ›¸ç›®è³‡è¨Š",
            "parameters": {
                "title": {"description": "æ–‡ç»æ¨™é¡Œ", "type": "str"},
                "authors": {"description": "ä½œè€…åˆ—è¡¨", "type": "list"},
                "year": {"description": "å‡ºç‰ˆå¹´ä»½", "type": "int"},
                "journal": {"description": "æœŸåˆŠåç¨±", "type": "str"},
                "doi": {"description": "DOI è­˜åˆ¥ç¢¼", "type": "str"}
            }
        },
        {
            "name": "generateCitation",
            "description": "ç”Ÿæˆå¼•ç”¨æ ¼å¼",
            "parameters": {
                "metadata": {"description": "æ›¸ç›®è³‡è¨Š", "type": "object"},
                "style": {"description": "å¼•ç”¨æ ¼å¼ï¼šAPAã€MLAã€Chicago", "type": "str"}
            }
        }
    ]
    
    # ç”Ÿæˆç¯„ä¾‹æŸ¥è©¢å’Œé æœŸå›æ‡‰
    overend_examples = [
        {
            "query_zhtw": "è«‹åˆ†æé€™æ®µå­¸è¡“å¯«ä½œï¼Œæª¢æŸ¥æ˜¯å¦æœ‰èªæ³•æˆ–é¢¨æ ¼å•é¡Œï¼šã€Œæˆ‘èªç‚ºé€™å€‹ç ”ç©¶å¾ˆæ£’ï¼Œçµæœè­‰æ˜æˆ‘å€‘çš„å‡è¨­æ˜¯å°çš„ã€‚ã€",
            "tools": overend_tools[:2],
            "think": """
å¥½çš„ï¼Œä½¿ç”¨è€…æƒ³è¦åˆ†æä¸€æ®µå­¸è¡“å¯«ä½œçš„èªæ³•å’Œé¢¨æ ¼å•é¡Œã€‚

é¦–å…ˆï¼Œæˆ‘éœ€è¦ç¢ºèªå¯ç”¨çš„å·¥å…·ã€‚æˆ‘çœ‹åˆ°æœ‰ "analyzeWriting" é€™å€‹å·¥å…·ï¼Œå®ƒå¯ä»¥åˆ†æå­¸è¡“å¯«ä½œå…§å®¹ï¼Œæª¢æŸ¥èªæ³•ã€é¢¨æ ¼å’Œé‚è¼¯å•é¡Œã€‚

æª¢è¦–åƒæ•¸ï¼š
- text: éœ€è¦æä¾›è¦åˆ†æçš„æ–‡æœ¬ï¼Œå°±æ˜¯ä½¿ç”¨è€…çµ¦çš„é‚£æ®µè©±
- academicMode: å› ç‚ºé€™æ˜¯å­¸è¡“å¯«ä½œï¼Œæ‡‰è©²è¨­ç‚º true

ä½¿ç”¨è€…æ˜ç¢ºèªªé€™æ˜¯ã€Œå­¸è¡“å¯«ä½œã€ï¼Œæ‰€ä»¥æˆ‘æ‡‰è©²å•Ÿç”¨å­¸è¡“æ¨¡å¼ã€‚é€™å€‹å·¥å…·æœƒæª¢æŸ¥ï¼š
1. èªæ³•å•é¡Œï¼ˆå¦‚æ¨™é»ç¬¦è™Ÿï¼‰
2. é¢¨æ ¼å•é¡Œï¼ˆå¦‚ã€Œæˆ‘èªç‚ºã€é€™ç¨®ç¬¬ä¸€äººç¨±ç”¨æ³•åœ¨å­¸è¡“å¯«ä½œä¸­ä¸å¤ªé©åˆï¼‰
3. é‚è¼¯å•é¡Œ

å› æ­¤ï¼Œæˆ‘å°‡å‘¼å« analyzeWriting å·¥å…·ï¼Œè¨­å®š academicMode ç‚º trueã€‚
""",
            "answer": [
                {
                    "name": "analyzeWriting",
                    "arguments": {
                        "text": "æˆ‘èªç‚ºé€™å€‹ç ”ç©¶å¾ˆæ£’ï¼Œçµæœè­‰æ˜æˆ‘å€‘çš„å‡è¨­æ˜¯å°çš„ã€‚",
                        "academicMode": True
                    }
                }
            ]
        },
        {
            "query_zhtw": "æˆ‘éœ€è¦å°‡é€™æ®µä¸­æ–‡æ‘˜è¦ç¿»è­¯æˆè‹±æ–‡ï¼Œä¸¦ä¸”ä¿æŒå­¸è¡“é¢¨æ ¼ï¼šã€Œæœ¬ç ”ç©¶æ¢è¨äººå·¥æ™ºæ…§åœ¨æ•™è‚²é ˜åŸŸçš„æ‡‰ç”¨ï¼Œé€éé‡åŒ–åˆ†æé©—è­‰å…¶æ•ˆæœã€‚ã€",
            "tools": overend_tools[2:3],
            "think": """
ä½¿ç”¨è€…éœ€è¦é€²è¡Œå­¸è¡“ç¿»è­¯ï¼Œå°‡ä¸­æ–‡ç¿»è­¯æˆè‹±æ–‡ã€‚

æª¢è¦–å¯ç”¨çš„å·¥å…·ï¼Œæœ‰ "translateAcademic" é€™å€‹åŠŸèƒ½å°ˆé–€ç”¨æ–¼å­¸è¡“ç¿»è­¯ï¼Œå¯ä»¥ä¿ç•™å°ˆæ¥­è¡“èªã€‚

åƒæ•¸è¨­å®šï¼š
- text: éœ€è¦ç¿»è­¯çš„ä¸­æ–‡æ‘˜è¦
- sourceLang: ä¾†æºèªè¨€æ˜¯ä¸­æ–‡ï¼Œæ‡‰è©²ç”¨ "zh-TW" æˆ– "Chinese"
- targetLang: ç›®æ¨™èªè¨€æ˜¯è‹±æ–‡ï¼Œæ‡‰è©²ç”¨ "en" æˆ– "English"

é€™å€‹å·¥å…·å¾ˆé©åˆé€™å€‹ä»»å‹™ï¼Œå› ç‚ºå®ƒæœƒä¿æŒå­¸è¡“é¢¨æ ¼ä¸¦æ­£ç¢ºè™•ç†è¡“èªå¦‚ã€Œé‡åŒ–åˆ†æã€ã€ã€Œäººå·¥æ™ºæ…§ã€ç­‰ã€‚
""",
            "answer": [
                {
                    "name": "translateAcademic",
                    "arguments": {
                        "text": "æœ¬ç ”ç©¶æ¢è¨äººå·¥æ™ºæ…§åœ¨æ•™è‚²é ˜åŸŸçš„æ‡‰ç”¨ï¼Œé€éé‡åŒ–åˆ†æé©—è­‰å…¶æ•ˆæœã€‚",
                        "sourceLang": "zh-TW",
                        "targetLang": "en"
                    }
                }
            ]
        },
        {
            "query_zhtw": "è«‹å°‡é€™æ®µæ–‡å­—æ”¹å¯«å¾—æ›´æ­£å¼ï¼šã€Œé€™ç¯‡è«–æ–‡å¯«å¾—ä¸éŒ¯ï¼Œä½†æœ‰äº›åœ°æ–¹å¯ä»¥æ›´å¥½ã€‚ã€",
            "tools": overend_tools[1:2],
            "think": """
ä½¿ç”¨è€…æƒ³è¦å°‡ä¸€æ®µæ¯”è¼ƒå£èªåŒ–çš„è©•è«–æ”¹å¯«æˆæ›´æ­£å¼çš„ç‰ˆæœ¬ã€‚

æŸ¥çœ‹å¯ç”¨å·¥å…·ï¼Œ"rewriteText" å¯ä»¥æ”¹å¯«æ–‡æœ¬ï¼Œä¸¦æ”¯æŒä¸åŒé¢¨æ ¼ã€‚

åƒæ•¸åˆ†æï¼š
- text: åŸå§‹æ–‡æœ¬å°±æ˜¯ä½¿ç”¨è€…çµ¦çš„é‚£å¥è©±
- style: ä½¿ç”¨è€…èªªè¦ã€Œæ›´æ­£å¼ã€ï¼Œæ‰€ä»¥æ‡‰è©²é¸æ“‡ "formal" æˆ– "academic"

ç”±æ–¼ä½¿ç”¨è€…æ˜ç¢ºè¦æ±‚ã€Œæ­£å¼ã€ï¼Œæˆ‘é¸æ“‡ style = "formal"ã€‚é€™æœƒå°‡å£èªåŒ–çš„è¡¨é”ï¼ˆå¦‚ã€Œä¸éŒ¯ã€ã€ã€Œå¯ä»¥æ›´å¥½ã€ï¼‰è½‰æ›ç‚ºæ­£å¼çš„æ›¸é¢èªã€‚
""",
            "answer": [
                {
                    "name": "rewriteText",
                    "arguments": {
                        "text": "é€™ç¯‡è«–æ–‡å¯«å¾—ä¸éŒ¯ï¼Œä½†æœ‰äº›åœ°æ–¹å¯ä»¥æ›´å¥½ã€‚",
                        "style": "formal"
                    }
                }
            ]
        }
    ]
    
    return overend_examples


# ========================================
# 4. ç”Ÿæˆæ”¹é€²å»ºè­°å ±å‘Š
# ========================================

def generate_improvement_report():
    """ç”Ÿæˆ OVEREND AI æ”¹é€²å»ºè­°å ±å‘Š"""
    
    report = """# OVEREND AI Tool Calling æ”¹é€²å»ºè­°

## åŸºæ–¼ tw-function-call-reasoning-10k è³‡æ–™é›†åˆ†æ

### 1. Chain-of-Thought æ¨ç†æ¨¡å¼åˆ†æ

å¾è³‡æ–™é›†ä¸­è§€å¯Ÿåˆ°çš„é«˜æ•ˆæ¨ç†æ¨¡å¼ï¼š

1. **å·¥å…·è­˜åˆ¥éšæ®µ**
   - é¦–å…ˆåˆ—å‡ºæ‰€æœ‰å¯ç”¨å·¥å…·
   - åˆ†ææ¯å€‹å·¥å…·çš„ç”¨é€”å’Œåƒæ•¸

2. **åƒæ•¸å°æ‡‰éšæ®µ**
   - é€ä¸€å°‡ä½¿ç”¨è€…éœ€æ±‚å°æ‡‰åˆ°å·¥å…·åƒæ•¸
   - è™•ç†é è¨­å€¼å’Œå¯é¸åƒæ•¸

3. **é©—è­‰éšæ®µ**
   - ç¢ºèªåƒæ•¸é¡å‹æ­£ç¢º
   - æª¢æŸ¥å¿…è¦åƒæ•¸æ˜¯å¦å®Œæ•´

### 2. æ¨è–¦çš„ Prompt çµæ§‹

```
ä½ æ˜¯ä¸€å€‹ [åŠŸèƒ½æè¿°] å°ˆå®¶ã€‚

å¯ç”¨å·¥å…·ï¼š
[å·¥å…·åˆ—è¡¨åŠæè¿°]

æ¨ç†æ­¥é©Ÿï¼š
1. é¦–å…ˆï¼Œè­˜åˆ¥ä½¿ç”¨è€…çš„å…·é«”éœ€æ±‚
2. ç„¶å¾Œï¼Œé¸æ“‡æœ€é©åˆçš„å·¥å…·
3. æ¥è‘—ï¼Œå°æ‡‰åƒæ•¸å€¼
4. æœ€å¾Œï¼Œé©—è­‰ä¸¦è¼¸å‡ºçµæœ

âš ï¸ æ³¨æ„äº‹é …ï¼š
- ä¸è¦ä½¿ç”¨ä½”ä½ç¬¦
- åƒæ•¸å€¼å¿…é ˆä¾†è‡ªä½¿ç”¨è€…è¼¸å…¥
- å¦‚æœæ‰¾ä¸åˆ°è³‡è¨Šï¼Œä½¿ç”¨ null æˆ–ç©ºå€¼
```

### 3. Few-shot ç¯„ä¾‹æ ¼å¼

æ¯å€‹ç¯„ä¾‹æ‡‰åŒ…å«ï¼š
- ä½¿ç”¨è€…æŒ‡ä»¤ï¼ˆç¹é«”ä¸­æ–‡ï¼‰
- å®Œæ•´çš„æ€è€ƒéç¨‹
- çµæ§‹åŒ–çš„å·¥å…·å‘¼å«çµæœ

### 4. å»ºè­°çš„æ”¹é€²é …ç›®

| å„ªå…ˆç´š | é …ç›® | èªªæ˜ |
|-------|------|------|
| P0 | åŠ å…¥ CoT æ¨ç† | åœ¨ Tool Calling å‰åŠ å…¥æ˜ç¢ºçš„æ€è€ƒæ­¥é©Ÿ |
| P1 | Few-shot ç¯„ä¾‹ | åœ¨ System Prompt ä¸­åŠ å…¥ 2-3 å€‹ç¯„ä¾‹ |
| P2 | åƒæ•¸é©—è­‰ | åŠ å…¥åƒæ•¸é¡å‹å’Œç¯„åœæª¢æŸ¥ |
| P3 | éŒ¯èª¤è™•ç† | ç•¶å¿…è¦è³‡è¨Šç¼ºå¤±æ™‚çš„é™ç´šç­–ç•¥ |

### 5. ç¾æœ‰ OVEREND Tools èˆ‡è³‡æ–™é›†å°æ‡‰

| OVEREND Tool | å°æ‡‰è³‡æ–™é›†ç¯„ä¾‹é¡å‹ | å»ºè­°æ”¹é€² |
|--------------|------------------|---------|
| extractPDFMetadata | è³‡è¨Šæå–é¡ | åŠ å…¥æ–‡ä»¶é¡å‹åˆ¤æ–·çš„ CoT |
| analyzeWriting | æ–‡æœ¬åˆ†æé¡ | åŠ å…¥å•é¡Œå„ªå…ˆç´šæ’åºé‚è¼¯ |
| rewriteText | æ–‡æœ¬è½‰æ›é¡ | åŠ å…¥é¢¨æ ¼ç‰¹å¾µæè¿° |
| translateAcademic | ç¿»è­¯é¡ | åŠ å…¥è¡“èªä¿ç•™é©—è­‰ |
| generateCitation | æ ¼å¼ç”Ÿæˆé¡ | åŠ å…¥å¼•ç”¨æ ¼å¼é©—è­‰ |

## ä¸‹ä¸€æ­¥è¡Œå‹•

1. [ ] æ›´æ–° ExtractPDFMetadataTool çš„ Instructionsï¼ŒåŠ å…¥ CoT æ¨¡å¼
2. [ ] åœ¨ WritingAIDomain ä¸­åŠ å…¥ Few-shot ç¯„ä¾‹
3. [ ] å»ºç«‹é©—è­‰æ¸¬è©¦æ¡ˆä¾‹
"""
    
    return report


# ========================================
# ä¸»ç¨‹å¼
# ========================================

def main():
    output_dir = Path("scripts/ai_enhancement")
    output_dir.mkdir(exist_ok=True)
    
    print("\n" + "=" * 70)
    print("ğŸ“Š 1. åˆ†æ Chain-of-Thought æ¨ç†æ¨¡å¼")
    print("=" * 70)
    
    patterns = analyze_cot_patterns(200)
    print("\nå¸¸è¦‹æ¨ç†æ¨¡å¼çµ±è¨ˆï¼ˆ200 å€‹æ¨£æœ¬ï¼‰ï¼š")
    for pattern, count in sorted(patterns.items(), key=lambda x: -x[1]):
        print(f"  - {pattern}: {count} æ¬¡ ({count/2:.1f}%)")
    
    print("\n" + "=" * 70)
    print("ğŸ“ 2. æå– Few-shot ç¯„ä¾‹")
    print("=" * 70)
    
    # æå–ä¸åŒé¡å‹çš„ç¯„ä¾‹
    search_examples = extract_fewshot_examples(['æœå°‹', 'æŸ¥è©¢', 'æ‰¾'], 3)
    convert_examples = extract_fewshot_examples(['è½‰æ›', 'æ”¹å¯«', 'ç¿»è­¯'], 3)
    analyze_examples = extract_fewshot_examples(['åˆ†æ', 'è¨ˆç®—', 'æª¢æŸ¥'], 3)
    
    print(f"\næ‰¾åˆ°ç¯„ä¾‹ï¼š")
    print(f"  - æœå°‹/æŸ¥è©¢é¡: {len(search_examples)} å€‹")
    print(f"  - è½‰æ›/æ”¹å¯«é¡: {len(convert_examples)} å€‹")
    print(f"  - åˆ†æ/è¨ˆç®—é¡: {len(analyze_examples)} å€‹")
    
    # å„²å­˜ç¯„ä¾‹
    all_examples = {
        'search': search_examples,
        'convert': convert_examples,
        'analyze': analyze_examples
    }
    
    with open(output_dir / 'fewshot_examples.json', 'w', encoding='utf-8') as f:
        json.dump(all_examples, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… å·²å„²å­˜åˆ° {output_dir / 'fewshot_examples.json'}")
    
    print("\n" + "=" * 70)
    print("ğŸ› ï¸ 3. ç”Ÿæˆ OVEREND å°ˆç”¨ç¯„ä¾‹")
    print("=" * 70)
    
    overend_examples = generate_overend_examples()
    
    with open(output_dir / 'overend_fewshot_examples.json', 'w', encoding='utf-8') as f:
        json.dump(overend_examples, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… å·²å„²å­˜ {len(overend_examples)} å€‹ OVEREND å°ˆç”¨ç¯„ä¾‹åˆ° {output_dir / 'overend_fewshot_examples.json'}")
    
    # é¡¯ç¤ºä¸€å€‹ç¯„ä¾‹
    print("\nğŸ“Œ ç¯„ä¾‹é è¦½:")
    ex = overend_examples[0]
    print(f"æŒ‡ä»¤: {ex['query_zhtw']}")
    print(f"æ€è€ƒéç¨‹: {ex['think'][:200]}...")
    print(f"ç­”æ¡ˆ: {json.dumps(ex['answer'], ensure_ascii=False)}")
    
    print("\n" + "=" * 70)
    print("ğŸ“‹ 4. ç”Ÿæˆæ”¹é€²å»ºè­°å ±å‘Š")
    print("=" * 70)
    
    report = generate_improvement_report()
    
    with open(output_dir / 'improvement_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"\nâœ… å·²å„²å­˜æ”¹é€²å»ºè­°å ±å‘Šåˆ° {output_dir / 'improvement_report.md'}")
    
    print("\n" + "=" * 70)
    print("ğŸ‰ å®Œæˆï¼")
    print("=" * 70)
    print(f"""
ç”Ÿæˆçš„æª”æ¡ˆï¼š
  ğŸ“ {output_dir}/
     â”œâ”€â”€ fewshot_examples.json      - å¾è³‡æ–™é›†æå–çš„ç¯„ä¾‹
     â”œâ”€â”€ overend_fewshot_examples.json - OVEREND å°ˆç”¨ç¯„ä¾‹
     â””â”€â”€ improvement_report.md      - AI æ”¹é€²å»ºè­°å ±å‘Š

ä¸‹ä¸€æ­¥ï¼š
  1. æŸ¥çœ‹ improvement_report.md äº†è§£æ”¹é€²å»ºè­°
  2. å°‡ overend_fewshot_examples.json ä¸­çš„ç¯„ä¾‹æ•´åˆåˆ° Prompt
  3. æ¸¬è©¦æ”¹é€²å¾Œçš„ Tool Calling æ•ˆæœ
""")


if __name__ == "__main__":
    main()
