 #!/usr/bin/env python3
"""
æ¸¬è©¦æ”¹é€²å¾Œçš„ OVEREND AI Tool Calling

é€™å€‹è…³æœ¬æ¨¡æ“¬ Apple Intelligence çš„ Tool Calling æµç¨‹ï¼Œ
ä½¿ç”¨æ”¹é€²å¾Œçš„ CoT æ¨ç†å’Œ Few-shot ç¯„ä¾‹ä¾†æ¸¬è©¦æ•ˆæœã€‚

ä½¿ç”¨æ–¹æ³•:
    source .venv/bin/activate
    python scripts/test_improved_ai.py
"""

import json
import os
from pathlib import Path

# æ¨¡æ“¬æ”¹é€²å¾Œçš„ Prompt
IMPROVED_PDF_EXTRACTION_PROMPT = """
ä½ æ˜¯å­¸è¡“æ–‡ç»æ›¸ç›®è­˜åˆ¥å°ˆå®¶ã€‚ä½ çš„ä»»å‹™æ˜¯å¾ PDF æ–‡å­—å…§å®¹ä¸­è­˜åˆ¥ä¸¦æå–çœŸå¯¦çš„æ›¸ç›®è³‡è¨Šã€‚

ğŸ“‹ æ¨ç†æ­¥é©Ÿï¼ˆChain-of-Thoughtï¼‰ï¼š

1. é¦–å…ˆï¼Œä»”ç´°é–±è®€ PDF å…§å®¹ï¼Œè­˜åˆ¥æ–‡ç»çš„çµæ§‹ã€‚
   - æ‰¾å‡ºæ¨™é¡Œå€åŸŸï¼ˆé€šå¸¸åœ¨æ–‡ä»¶é–‹é ­ï¼Œå­—é«”è¼ƒå¤§æˆ–åŠ ç²—ï¼‰
   - æ‰¾å‡ºä½œè€…å€åŸŸï¼ˆé€šå¸¸åœ¨æ¨™é¡Œä¸‹æ–¹ï¼‰
   - æ‰¾å‡ºå‡ºç‰ˆè³‡è¨Šå€åŸŸï¼ˆå¯èƒ½åŒ…å«å¹´ä»½ã€æœŸåˆŠåç¨±ã€DOIï¼‰

2. ç„¶å¾Œï¼Œé€ä¸€æå–å„å€‹æ¬„ä½ï¼š
   - æ¨™é¡Œï¼šæ‰¾åˆ°å¯¦éš›çš„å®Œæ•´æ¨™é¡Œæ–‡å­—
   - ä½œè€…ï¼šåˆ—å‡ºæ‰€æœ‰ä½œè€…çš„çœŸå¯¦å§“å
   - å¹´ä»½ï¼šæ‰¾åˆ°å››ä½æ•¸çš„å‡ºç‰ˆå¹´ä»½
   - æœŸåˆŠ/æœƒè­°ï¼šæ‰¾åˆ°ç™¼è¡¨ä¾†æºåç¨±
   - DOIï¼šæ‰¾åˆ°ä»¥ 10. é–‹é ­çš„è­˜åˆ¥ç¢¼

3. æ¥è‘—ï¼Œé©—è­‰æå–çš„è³‡è¨Šï¼š
   - ç¢ºèªæ¨™é¡Œä¸æ˜¯ä½”ä½ç¬¦ï¼ˆå¦‚ã€Œè«–æ–‡æ¨™é¡Œã€ã€ŒPaper Titleã€ï¼‰
   - ç¢ºèªä½œè€…ä¸æ˜¯å‡åï¼ˆå¦‚ã€Œä½œè€…1ã€ã€Œå¼µä¸‰ã€ã€ŒJohn Doeã€ï¼‰
   - ç¢ºèªå¹´ä»½æ˜¯åˆç†çš„ï¼ˆé€šå¸¸åœ¨ 1900-2026 ä¹‹é–“ï¼‰

4. æœ€å¾Œï¼Œåˆ¤æ–·æ–‡ç»é¡å‹ä¸¦èª¿ç”¨å·¥å…·ï¼š
   - article: æœŸåˆŠæ–‡ç« ï¼ˆæœ‰æœŸåˆŠåç¨±ã€å·æœŸé ç¢¼ï¼‰
   - inproceedings: æœƒè­°è«–æ–‡ï¼ˆæœ‰æœƒè­°åç¨±ï¼‰
   - thesis: å­¸ä½è«–æ–‡ï¼ˆæœ‰å­¸æ ¡åç¨±ã€å­¸ä½é¡å‹ï¼‰
   - book: æ›¸ç±ï¼ˆæœ‰å‡ºç‰ˆç¤¾ã€ISBNï¼‰
   - misc: ç„¡æ³•ç¢ºå®šé¡å‹

ğŸ“ ç¯„ä¾‹ï¼ˆFew-shotï¼‰ï¼š

ç¯„ä¾‹ 1 - æœŸåˆŠæ–‡ç« æå–ï¼š
è¼¸å…¥ï¼šã€ŒDeep Learning for Natural Language Processing: A Survey
       Authors: John Smith, Mary Johnson
       Published in: Journal of AI Research, 2023
       DOI: 10.1016/j.jair.2023.01.001ã€
æ€è€ƒï¼šé€™æ˜¯ä¸€ç¯‡æœŸåˆŠæ–‡ç« ï¼Œæ¨™é¡Œæ˜¯ã€ŒDeep Learning for Natural Language Processing: A Surveyã€ï¼Œ
      ä½œè€…æœ‰å…©ä½ John Smith å’Œ Mary Johnsonï¼Œç™¼è¡¨æ–¼ 2023 å¹´çš„ Journal of AI Researchã€‚
çµæœï¼štitle="Deep Learning for Natural Language Processing: A Survey",
      authors=["John Smith", "Mary Johnson"], year="2023",
      journal="Journal of AI Research", doi="10.1016/j.jair.2023.01.001",
      documentType=article

ç¯„ä¾‹ 2 - è³‡è¨Šç¼ºå¤±è™•ç†ï¼š
è¼¸å…¥ï¼šã€Œç ”ç©¶æ–¹æ³•è«–æ¢è¨
       ï¼ˆæ–‡ä»¶å…§å®¹æ¨¡ç³Šï¼Œç„¡æ³•è¾¨è­˜ä½œè€…å’Œå‡ºç‰ˆè³‡è¨Šï¼‰ã€
æ€è€ƒï¼šåªèƒ½è­˜åˆ¥åˆ°æ¨™é¡Œï¼Œå…¶ä»–è³‡è¨Šç„¡æ³•ç¢ºå®šï¼Œæ‡‰è©²å¡«å…¥ç©ºå€¼è€ŒéçŒœæ¸¬ã€‚
çµæœï¼štitle="ç ”ç©¶æ–¹æ³•è«–æ¢è¨", authors=[], year=null,
      journal=null, doi=null, documentType=misc
"""

IMPROVED_WRITING_ANALYSIS_PROMPT = """
ä½ æ˜¯å°ˆæ¥­çš„å¯«ä½œåˆ†æå°ˆå®¶ã€‚

ğŸ“‹ æ¨ç†æ­¥é©Ÿï¼ˆChain-of-Thoughtï¼‰ï¼š

1. é¦–å…ˆï¼Œé€šè®€æ•´æ®µæ–‡å­—ï¼Œç†è§£æ•´é«”å…§å®¹å’Œèªå¢ƒã€‚

2. ç„¶å¾Œï¼Œæª¢æŸ¥èªæ³•å•é¡Œï¼š
   - æ¨™é»ç¬¦è™Ÿä½¿ç”¨æ˜¯å¦æ­£ç¢º
   - å¥å­çµæ§‹æ˜¯å¦å®Œæ•´
   - ä¸»è¬‚è³“æ˜¯å¦æ­é…

3. æ¥è‘—ï¼Œæª¢æŸ¥é¢¨æ ¼å•é¡Œï¼š
   - æ˜¯å¦æœ‰å£èªåŒ–è¡¨é”
   - æ˜¯å¦æœ‰ä¸ç•¶çš„äººç¨±ä½¿ç”¨
   - ç”¨è©æ˜¯å¦æ°ç•¶

4. æœ€å¾Œï¼Œæª¢æŸ¥é‚è¼¯å•é¡Œï¼š
   - è«–è¿°æ˜¯å¦é€£è²«
   - å› æœé—œä¿‚æ˜¯å¦æ¸…æ™°
   - æ˜¯å¦æœ‰çŸ›ç›¾ä¹‹è™•

ğŸ“ ç¯„ä¾‹ï¼ˆFew-shotï¼‰ï¼š

ç¯„ä¾‹ 1 - å­¸è¡“å¯«ä½œåˆ†æï¼š
è¼¸å…¥ï¼šã€Œæˆ‘èªç‚ºé€™å€‹ç ”ç©¶å¾ˆæ£’ï¼Œçµæœè­‰æ˜æˆ‘å€‘çš„å‡è¨­æ˜¯å°çš„ã€‚ã€
æ€è€ƒï¼šé€™æ®µæ–‡å­—æœ‰å¹¾å€‹å­¸è¡“å¯«ä½œå•é¡Œï¼š
      1. ä½¿ç”¨ç¬¬ä¸€äººç¨±ã€Œæˆ‘ã€ã€Œæˆ‘å€‘ã€
      2. å£èªåŒ–è¡¨é”ã€Œå¾ˆæ£’ã€
      3. éæ–¼ä¸»è§€çš„åˆ¤æ–·
çµæœï¼š
- styleIssues: [
    {original: "æˆ‘èªç‚º", suggestion: "æœ¬ç ”ç©¶èªç‚º", explanation: "å­¸è¡“å¯«ä½œæ‡‰é¿å…ç¬¬ä¸€äººç¨±", severity: "high"},
    {original: "å¾ˆæ£’", suggestion: "å…·æœ‰é‡è¦æ„ç¾©", explanation: "æ‡‰ä½¿ç”¨å®¢è§€å­¸è¡“ç”¨èª", severity: "medium"},
    {original: "æˆ‘å€‘çš„", suggestion: "æœ¬ç ”ç©¶çš„", explanation: "ä½¿ç”¨ç¬¬ä¸‰äººç¨±è¡¨è¿°", severity: "high"}
  ]
- overallFeedback: "æ–‡å­—æ•´é«”æµæš¢ï¼Œä½†éœ€èª¿æ•´ç‚ºå­¸è¡“å¯«ä½œé¢¨æ ¼"
"""


# ========================================
# æ¸¬è©¦ç”¨ä¾‹
# ========================================

PDF_TEST_CASES = [
    {
        "name": "æœŸåˆŠæ–‡ç«  - æ¸…æ™°è³‡è¨Š",
        "input": """
Attention Is All You Need

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin

Abstract: The dominant sequence transduction models are based on complex recurrent or
convolutional neural networks...

Published in: Advances in Neural Information Processing Systems 30 (NIPS 2017)
arXiv:1706.03762
        """,
        "expected": {
            "title": "Attention Is All You Need",
            "authors": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin"],
            "year": "2017",
            "documentType": "inproceedings"
        }
    },
    {
        "name": "ä¸­æ–‡è«–æ–‡",
        "input": """
äººå·¥æ™ºæ…§åœ¨æ•™è‚²é ˜åŸŸçš„æ‡‰ç”¨èˆ‡æŒ‘æˆ°

ä½œè€…ï¼šé™³æ˜å¿—ã€æ—é›…å©·ã€ç‹å»ºåœ‹

æ‘˜è¦ï¼šæœ¬ç ”ç©¶æ¢è¨äººå·¥æ™ºæ…§æŠ€è¡“åœ¨æ•™è‚²å ´åŸŸä¸­çš„å¯¦éš›æ‡‰ç”¨...

ç™¼è¡¨æ–¼ï¼šã€Šæ•™è‚²ç§‘æŠ€æœŸåˆŠã€‹2024å¹´ç¬¬15å·ç¬¬3æœŸ
DOI: 10.6178/JETS.202403.15(3).001
        """,
        "expected": {
            "title": "äººå·¥æ™ºæ…§åœ¨æ•™è‚²é ˜åŸŸçš„æ‡‰ç”¨èˆ‡æŒ‘æˆ°",
            "authors": ["é™³æ˜å¿—", "æ—é›…å©·", "ç‹å»ºåœ‹"],
            "year": "2024",
            "journal": "æ•™è‚²ç§‘æŠ€æœŸåˆŠ",
            "doi": "10.6178/JETS.202403.15(3).001",
            "documentType": "article"
        }
    },
    {
        "name": "è³‡è¨Šç¼ºå¤±æƒ…æ³",
        "input": """
[æƒææ–‡ä»¶ - å½±åƒæ¨¡ç³Š]

...ç ”ç©¶æ–¹æ³•è«–çš„é‡è¦æ€§...
...ç„¡æ³•è¾¨è­˜å…¶ä»–å…§å®¹...
        """,
        "expected": {
            "title": "",  # ç„¡æ³•è­˜åˆ¥ï¼Œæ‡‰è¿”å›ç©º
            "authors": [],
            "year": None,
            "documentType": "misc"
        }
    }
]

WRITING_TEST_CASES = [
    {
        "name": "å­¸è¡“å¯«ä½œ - å¤šè™•å•é¡Œ",
        "input": "æˆ‘èªç‚ºé€™å€‹ç ”ç©¶å¾ˆæ£’ï¼Œçµæœè­‰æ˜æˆ‘å€‘çš„å‡è¨­æ˜¯å°çš„ã€‚å¤§å®¶éƒ½çŸ¥é“é€™å€‹æ–¹æ³•æ˜¯æœ€å¥½çš„ã€‚",
        "expected_issues": {
            "styleIssues": [
                {"original": "æˆ‘èªç‚º", "suggestion": "æœ¬ç ”ç©¶èªç‚º"},
                {"original": "å¾ˆæ£’", "suggestion": "å…·æœ‰é‡è¦æ„ç¾©"},
                {"original": "æˆ‘å€‘çš„", "suggestion": "æœ¬ç ”ç©¶çš„"},
                {"original": "å¤§å®¶éƒ½çŸ¥é“", "suggestion": "æ™®éèªç‚º"},
                {"original": "æœ€å¥½çš„", "suggestion": "è¼ƒç‚ºæœ‰æ•ˆçš„"}
            ]
        }
    },
    {
        "name": "å­¸è¡“å¯«ä½œ - ç„¡å•é¡Œ",
        "input": "æœ¬ç ”ç©¶é€éå¯¦è­‰åˆ†æé©—è­‰äº†å‡è¨­ï¼Œçµæœé¡¯ç¤ºè®Šæ•¸é–“å­˜åœ¨é¡¯è‘—ç›¸é—œã€‚",
        "expected_issues": {
            "styleIssues": [],
            "grammarIssues": [],
            "logicIssues": []
        }
    },
    {
        "name": "èªæ³•å•é¡Œ",
        "input": "é€™å€‹ç ”ç©¶å¾ˆé‡è¦ã€‚ã€‚å› ç‚ºå®ƒå¯ä»¥å¹«åŠ©æˆ‘å€‘ç†è§£ï¼Œï¼Œå•é¡Œçš„æœ¬è³ªã€‚",
        "expected_issues": {
            "grammarIssues": [
                {"original": "ã€‚ã€‚", "suggestion": "ã€‚"},
                {"original": "ï¼Œï¼Œ", "suggestion": "ï¼Œ"}
            ]
        }
    }
]


def simulate_cot_reasoning(prompt: str, input_text: str) -> dict:
    """æ¨¡æ“¬ Chain-of-Thought æ¨ç†éç¨‹"""
    print(f"\n{'='*60}")
    print("ğŸ¤– æ¨¡æ“¬ AI æ¨ç†éç¨‹")
    print(f"{'='*60}")
    
    # é¡¯ç¤ºæ¨ç†æ­¥é©Ÿ
    steps = [
        "1ï¸âƒ£ é¦–å…ˆï¼Œé–±è®€ä¸¦ç†è§£è¼¸å…¥å…§å®¹...",
        "2ï¸âƒ£ ç„¶å¾Œï¼Œè­˜åˆ¥é—œéµè³‡è¨Šå€åŸŸ...",
        "3ï¸âƒ£ æ¥è‘—ï¼Œæå–ä¸¦é©—è­‰å„æ¬„ä½...",
        "4ï¸âƒ£ æœ€å¾Œï¼Œåˆ¤æ–·é¡å‹ä¸¦ç”Ÿæˆçµæœ..."
    ]
    
    for step in steps:
        print(f"   {step}")
    
    print(f"\nğŸ“ è¼¸å…¥å…§å®¹é è¦½:")
    print(f"   {input_text[:100]}...")
    
    return {"status": "simulated"}


def test_pdf_extraction():
    """æ¸¬è©¦ PDF å…ƒæ•¸æ“šæå–"""
    print("\n" + "="*70)
    print("ğŸ“„ æ¸¬è©¦ PDF å…ƒæ•¸æ“šæå– (æ”¹é€²ç‰ˆ)")
    print("="*70)
    
    results = []
    
    for i, case in enumerate(PDF_TEST_CASES):
        print(f"\n--- æ¸¬è©¦æ¡ˆä¾‹ {i+1}: {case['name']} ---")
        
        # æ¨¡æ“¬æ¨ç†éç¨‹
        simulate_cot_reasoning(IMPROVED_PDF_EXTRACTION_PROMPT, case['input'])
        
        # é¡¯ç¤ºé æœŸçµæœ
        print(f"\nâœ… é æœŸæå–çµæœ:")
        for key, value in case['expected'].items():
            print(f"   - {key}: {value}")
        
        results.append({
            "name": case['name'],
            "status": "å¾…å¯¦æ©Ÿæ¸¬è©¦",
            "expected": case['expected']
        })
    
    return results


def test_writing_analysis():
    """æ¸¬è©¦å¯«ä½œåˆ†æ"""
    print("\n" + "="*70)
    print("âœï¸ æ¸¬è©¦å¯«ä½œåˆ†æ (æ”¹é€²ç‰ˆ)")
    print("="*70)
    
    results = []
    
    for i, case in enumerate(WRITING_TEST_CASES):
        print(f"\n--- æ¸¬è©¦æ¡ˆä¾‹ {i+1}: {case['name']} ---")
        print(f"ğŸ“ è¼¸å…¥: {case['input']}")
        
        # æ¨¡æ“¬æ¨ç†éç¨‹
        print("\nğŸ¤– æ¨¡æ“¬ AI æ¨ç†éç¨‹:")
        print("   1ï¸âƒ£ é€šè®€æ•´æ®µæ–‡å­—ï¼Œç†è§£èªå¢ƒ...")
        print("   2ï¸âƒ£ æª¢æŸ¥èªæ³•å•é¡Œ...")
        print("   3ï¸âƒ£ æª¢æŸ¥é¢¨æ ¼å•é¡Œ...")
        print("   4ï¸âƒ£ æª¢æŸ¥é‚è¼¯å•é¡Œ...")
        
        # é¡¯ç¤ºé æœŸçµæœ
        print(f"\nâœ… é æœŸæª¢æ¸¬åˆ°çš„å•é¡Œ:")
        for issue_type, issues in case['expected_issues'].items():
            if issues:
                print(f"   {issue_type}: {len(issues)} å€‹å•é¡Œ")
                for issue in issues[:3]:  # åªé¡¯ç¤ºå‰3å€‹
                    print(f"      - \"{issue['original']}\" â†’ \"{issue['suggestion']}\"")
            else:
                print(f"   {issue_type}: ç„¡å•é¡Œ âœ“")
        
        results.append({
            "name": case['name'],
            "status": "å¾…å¯¦æ©Ÿæ¸¬è©¦",
            "expected_issues": case['expected_issues']
        })
    
    return results


def generate_test_report(pdf_results, writing_results):
    """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
    report = {
        "test_date": "2026-01-11",
        "improvements_applied": [
            "Chain-of-Thought æ¨ç†æ­¥é©Ÿ",
            "Few-shot ç¯„ä¾‹",
            "ä½”ä½ç¬¦éæ¿¾é‚è¼¯"
        ],
        "pdf_extraction_tests": pdf_results,
        "writing_analysis_tests": writing_results,
        "notes": "é€™äº›æ¸¬è©¦æ¡ˆä¾‹éœ€è¦åœ¨å¯¦éš› macOS 26.0 ç’°å¢ƒä¸­ç”¨ Apple Intelligence é©—è­‰"
    }
    
    output_dir = Path("scripts/ai_enhancement")
    output_dir.mkdir(exist_ok=True)
    
    with open(output_dir / "test_report.json", 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æ¸¬è©¦å ±å‘Šå·²å„²å­˜åˆ° {output_dir / 'test_report.json'}")
    
    return report


def main():
    print("="*70)
    print("ğŸ§ª OVEREND AI Tool Calling æ”¹é€²æ¸¬è©¦")
    print("="*70)
    print("\né€™å€‹è…³æœ¬æ¨¡æ“¬æ”¹é€²å¾Œçš„ AI æ¨ç†æµç¨‹ï¼Œ")
    print("é©—è­‰ CoT æ¨ç†æ­¥é©Ÿå’Œ Few-shot ç¯„ä¾‹çš„è¨­è¨ˆã€‚\n")
    
    # æ¸¬è©¦ PDF æå–
    pdf_results = test_pdf_extraction()
    
    # æ¸¬è©¦å¯«ä½œåˆ†æ
    writing_results = test_writing_analysis()
    
    # ç”Ÿæˆå ±å‘Š
    generate_test_report(pdf_results, writing_results)
    
    # ç¸½çµ
    print("\n" + "="*70)
    print("ğŸ“Š æ¸¬è©¦ç¸½çµ")
    print("="*70)
    print(f"""
æ”¹é€²å…§å®¹ï¼š
  âœ… ExtractPDFMetadataTool: åŠ å…¥ CoT + Few-shot
  âœ… AnalyzeWritingTool: åŠ å…¥ CoT + Few-shot
  âœ… ç·¨è­¯é©—è­‰é€šé

æ¸¬è©¦æ¡ˆä¾‹ï¼š
  ğŸ“„ PDF æå–: {len(pdf_results)} å€‹æ¡ˆä¾‹
  âœï¸ å¯«ä½œåˆ†æ: {len(writing_results)} å€‹æ¡ˆä¾‹

ä¸‹ä¸€æ­¥ï¼š
  1. åœ¨ OVEREND æ‡‰ç”¨ä¸­å¯¦éš›æ¸¬è©¦é€™äº›æ¡ˆä¾‹
  2. è§€å¯Ÿ Tool Calling çš„æº–ç¢ºåº¦è®ŠåŒ–
  3. æ ¹æ“šçµæœé€²ä¸€æ­¥èª¿æ•´ Prompt

æç¤ºï¼šå¯ä»¥åœ¨ Xcode åŸ·è¡Œæ‡‰ç”¨ï¼ŒåŒ¯å…¥ PDF æ–‡ä»¶ä¾†æ¸¬è©¦æ”¹é€²æ•ˆæœã€‚
""")


if __name__ == "__main__":
    main()
